Part of work undertaken with Prof. Dimitris Papiliopolus at UW Madison during Fall 2018. 

Various notions of fairness for constraining Machine Learning models to eliminate/mitigate the bias against sub population groups based on protected attributes in a supervised learning framework were surveyed.

Lot of research on algorithmic fairness has been devoted to the study of group fairness. These approaches constrain the classifier to equalize a defined fairness metric across all groups. 
